{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from filecmp import dircmp\n",
    "from os import listdir\n",
    "import os\n",
    "import filecmp\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely import wkt\n",
    "import shapely\n",
    "from sqlalchemy import create_engine\n",
    "from shapely.geometry import shape\n",
    "from shapely.ops import unary_union\n",
    "from geopandas import GeoDataFrame\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "import networkx as nx\n",
    "from shapely.geometry import MultiPolygon\n",
    "import datetime as dt\n",
    "from pystac_client import Client\n",
    "from holoviews import opts\n",
    "from intake import open_catalog\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catfeux = open_catalog(f'{os.getenv(\"PROJECT_PATH\")}Fire_Detection_Data_Quality.yaml')\n",
    "\n",
    "date_start=datetime(2024,1,1)\n",
    "date_end=datetime(2024,3,31)\n",
    "\n",
    "table_source='surfaces_brulees_brute_control'\n",
    "sql = f\"\"\"SELECT *\n",
    "FROM feux_cq.{table_source} si\n",
    "WHERE si.date_ >= '{pd.to_datetime(date_start).strftime('%Y-%m-%d')}' AND si.date_ <= '{pd.to_datetime(date_end).strftime('%Y-%m-%d')}'\n",
    "\"\"\"\n",
    "\n",
    "dataCatalog = getattr(catfeux, table_source)(sql_expr=sql)\n",
    "surfdetect_control = dataCatalog.read()\n",
    "\n",
    "tile_sentinel=catfeux.tile_sentinel2_line_UTM.read()\n",
    "tile_sentinel=tile_sentinel.to_crs(epsg=4326)\n",
    "\n",
    "nc_limits=catfeux.nc_limits.read()\n",
    "nc_limits=nc_limits.to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon, mapping\n",
    "from bokeh.models import ColumnDataSource, HoverTool, LogColorMapper\n",
    "\n",
    "def linestring_to_polygon(gdf):\n",
    "    polygons = []\n",
    "    \n",
    "    for index, row in gdf.iterrows():\n",
    "        all_coords = mapping(row['geometry'])['coordinates']\n",
    "        lats = [x[1] for x in all_coords]\n",
    "        lons = [x[0] for x in all_coords]\n",
    "        \n",
    "        polyg = Polygon(zip(lons, lats))\n",
    "        polygons.append(polyg)\n",
    "    new_gdf = gpd.GeoDataFrame(geometry=polygons, crs=gdf.crs)\n",
    "    \n",
    "    return new_gdf\n",
    "\n",
    "test = linestring_to_polygon(tile_sentinel)\n",
    "tile_sentinel['geometry']=test['geometry']\n",
    "tile_sentinel['Name']='L2A_T'+tile_sentinel['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid = (tile_sentinel.centroid)\n",
    "centroid_tuile = pd.DataFrame(centroid)\n",
    "\n",
    "centroid_tuile['x']=centroid.x\n",
    "centroid_tuile['y']=centroid.y\n",
    "centroid_tuile['nom']=tile_sentinel['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPolyCoords(row, geom, coord_type):\n",
    "    \"\"\"Returns the coordinates ('x' or 'y') of edges of a Polygon exterior\"\"\"\n",
    "    exterior = row[geom].exterior\n",
    "\n",
    "    if coord_type == 'x':\n",
    "        return list( exterior.coords.xy[0] )\n",
    "    elif coord_type == 'y':\n",
    "        return list( exterior.coords.xy[1] )\n",
    "\n",
    "\n",
    "tile_sentinel['x'] = tile_sentinel.apply(getPolyCoords, geom='geometry', coord_type='x', axis=1)\n",
    "tile_sentinel['y'] = tile_sentinel.apply(getPolyCoords, geom='geometry', coord_type='y', axis=1)\n",
    "\n",
    "m_df = tile_sentinel.drop('geometry', axis=1).copy()\n",
    "tuile = ColumnDataSource(m_df)\n",
    "\n",
    "nc_limits=nc_limits.explode()\n",
    "nc_limits['x'] = nc_limits.apply(getPolyCoords, geom='shape', coord_type='x', axis=1)\n",
    "nc_limits['y'] = nc_limits.apply(getPolyCoords, geom='shape', coord_type='y', axis=1)\n",
    "\n",
    "m_df_2 = nc_limits.drop('shape', axis=1).copy()\n",
    "nc = ColumnDataSource(m_df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find detection type : \"Mono detection\" or \"pluri detection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_intersecting_id(row, gdf):\n",
    "\n",
    "    possible_matches_index = list(gdf.sindex.intersection(row['geometry'].bounds))\n",
    "    possible_matches = gdf.iloc[possible_matches_index]\n",
    "    precise_matches = possible_matches[possible_matches.geometry.intersects(row['geometry'])]\n",
    "    intersecting_ids = precise_matches['surface_id_h3'].tolist()\n",
    "    intersecting_ids = [id_ for id_ in intersecting_ids if id_ != row['surface_id_h3']]\n",
    "    return intersecting_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mesure_totale(df):\n",
    "    tot_nb=len(df) #number total of detection \n",
    "    tot_surf=df.dissolve() ## total number of detected area (ha)\n",
    "    tot_surf=pd.Series(tot_surf.area/10000)\n",
    "    tot_surf=tot_surf.reset_index(drop=True)\n",
    "    tot_surf=tot_surf[0]\n",
    "    \n",
    "    tot_surf_tile=df.dissolve(by='nom')\n",
    "    tot_surf_tile=pd.DataFrame(tot_surf_tile.area/10000)\n",
    "    tot_surf_tile['nom']=tot_surf_tile.index\n",
    "    tot_surf_tile=tot_surf_tile.reset_index(drop=True)\n",
    "\n",
    "    return(tot_surf,tot_nb,tot_surf_tile)\n",
    "\n",
    "def mesure_pluri_detection(df):\n",
    "    pluri_detection_list=df[df['groupe_id'].notna()]\n",
    "    pluri_detection_surface=pluri_detection_list.dissolve() ## number of pluri detected detected area (ha)\n",
    "    pluri_detection_surface=pd.Series(pluri_detection_surface.area/10000)\n",
    "    pluri_detection_surface=pluri_detection_surface.reset_index(drop=True)\n",
    "    pluri_detection_surface=pluri_detection_surface[0]\n",
    "\n",
    "    pluri_detection_group=pluri_detection_list['groupe_id'].nunique() ## number of group\n",
    "    pluri_tile_number = pd.DataFrame(pluri_detection_list[\"nom\"].value_counts())\n",
    "    \n",
    "    pluri_tile_surface=pluri_detection_list.dissolve(by='nom')\n",
    "    pluri_tile_surface=pd.DataFrame(pluri_tile_surface.area/10000)\n",
    "    pluri_tile_surface['nom']=pluri_tile_surface.index\n",
    "    pluri_tile_surface=pluri_tile_surface.reset_index(drop=True)\n",
    "    \n",
    "    return(pluri_tile_surface,pluri_tile_number,pluri_detection_group,pluri_detection_surface)\n",
    "\n",
    "def mesure_mono_detection(df):\n",
    "    mono_detection_list=df[df['groupe_id'].isna()]\n",
    "    mono_detection_surface=mono_detection_list['surface'].sum() ## number of mono detected detected area (ha)\n",
    "    mono_detection_group=mono_detection_list['groupe_id'].isna().sum() ## number of mono detected polygons\n",
    "\n",
    "    mono_tile_number = pd.DataFrame(mono_detection_list[\"nom\"].value_counts()) ## number of detection per tiles\n",
    "    mono_tile_surface = mono_detection_list.groupby('nom')['surface'].sum().reset_index() ## sum of burned area detected per tile\n",
    "    \n",
    "    return(mono_tile_surface,mono_tile_number,mono_detection_group,mono_detection_surface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_multiple_date_formats(date_str, formats):\n",
    "    for fmt in formats:\n",
    "        try:\n",
    "            return pd.to_datetime(date_str, format=fmt)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return pd.NaT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stac_search(date_start,date_end):\n",
    "    from pystac_client import Client\n",
    "\n",
    "    catalog = Client.open(\"https://earth-search.aws.element84.com/v1\")\n",
    "    query = catalog.search(\n",
    "        collections=[\"sentinel-2-l2a\"],datetime=(date_start).strftime('%Y-%m-%d')+'/'+(date_end).strftime('%Y-%m-%d'), bbox=[163.362, -22.76, 168.223, -19.479],        fields={\"include\": [\"properties.grid:code\", \"properties.datetime\", \"properties.eo:cloud_cover\", \"assets.thumbnail.href\"], \"exclude\": []}\n",
    "    )\n",
    "\n",
    "    items = list(query.items())\n",
    "    stac_json = query.item_collection_as_dict()\n",
    "\n",
    "    gdf = gpd.GeoDataFrame.from_features(stac_json, \"epsg:4326\")\n",
    "    thumbnails = [item.assets['thumbnail'].href for item in items]\n",
    "\n",
    "    df = gdf.rename(columns={\n",
    "        'grid:code': 'nom',\n",
    "        'datetime': 'date_',\n",
    "        'eo:cloud_cover': 'Cloud_Cover',\n",
    "        'thumbnail.href': 'thumbnail'\n",
    "    })\n",
    "\n",
    "    df['nom'] = [x[5:] for x in df['nom']]\n",
    "    df['nom']='L2A_T'+df['nom'] \n",
    "\n",
    "    df=df.reset_index(drop=True)\n",
    "    date_formats = ['%Y-%m-%dT%H:%M:%SZ', '%Y-%m-%d %H:%M:%S.%f%z','%Y-%m-%dT%H:%M:%S.%fZ']\n",
    "    df['date_'] = df['date_'].apply(try_multiple_date_formats, formats=date_formats)\n",
    "    df['date_'] = df['date_'].dt.strftime('%Y-%m-%d')\n",
    "    df['date_'] = pd.to_datetime(df['date_'])\n",
    "    \n",
    "    df['thumbnail_url'] = thumbnails\n",
    "    df = df.sort_values(by='date_', ascending=True)\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_formatter(plot, element):\n",
    "    formatter = DatetimeTickFormatter(\n",
    "        microseconds=[\"%Y-%m-%d\"],\n",
    "        milliseconds=[\"%Y-%m-%d\"],\n",
    "        seconds=[\"%Y-%m-%d\"],\n",
    "        minsec=[\"%Y-%m-%d\"],\n",
    "        minutes=[\"%Y-%m-%d\"],\n",
    "        hourmin=[\"%Y-%m-%d\"],\n",
    "        hours=[\"%Y-%m-%d\"],\n",
    "        days=[\"%Y-%m-%d\"],\n",
    "        months=[\"%Y-%m-%d\"],\n",
    "        years=[\"%Y-%m-%d\"],\n",
    "    )\n",
    "    plot.handles['xaxis'].formatter = formatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "import numpy as np\n",
    "from bokeh.models import HoverTool\n",
    "from bokeh.palettes import RdYlBu11 as palette\n",
    "from bokeh.models import LogColorMapper\n",
    "from bokeh.tile_providers import OSM, get_provider\n",
    "from bokeh.plotting import figure\n",
    "import datetime as dt\n",
    "from odc.stac import configure_rio, stac_load\n",
    "import matplotlib.pyplot as plt\n",
    "import holoviews as hv\n",
    "from bokeh.models import ColumnDataSource, DatetimeTickFormatter\n",
    "from bokeh.models.formatters import DatetimeTickFormatter\n",
    "from odc.stac import configure_rio, stac_load\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import hvplot.pandas \n",
    "\n",
    "pn.extension()\n",
    "pn.extension('tabulator')\n",
    "\n",
    "stylesheet = \"\"\"\n",
    ".tabulator-cell {\n",
    "    font-size: 20px;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "custom_style = {\n",
    "    'background': '#f89424',\n",
    "    'border': '1px solid black',\n",
    "    'padding': '10px',\n",
    "    'box-shadow': '5px 5px 5px #bcbcbc'\n",
    "}\n",
    "    \n",
    "def highlight_max(s):\n",
    "    '''\n",
    "    highlight the maximum in a Series yellow.\n",
    "    '''\n",
    "    is_max = s == s.max()\n",
    "    return ['background-color: f89424' if v else '' for v in is_max]\n",
    "\n",
    "tile_bouton = pn.widgets.RadioButtonGroup(options=['L2A_T58KCC','L2A_T58KCD','L2A_T58KDB','L2A_T58KDC','L2A_T58KEA','L2A_T58KEB','L2A_T58KEC',\n",
    "            'L2A_T58KFA','L2A_T58KFB','L2A_T58KFC','L2A_T58KGA','L2A_T58KGB','L2A_T58KGC','L2A_T58KGV','L2A_T58KHB'],align='center',stylesheets=[stylesheet],\n",
    "            button_type='warning',button_style='outline',name='Choose a tile')\n",
    "\n",
    "### PAGE 1 #########\n",
    "############ table\n",
    "\n",
    "def maj_table(date_range):\n",
    "    hv.extension('bokeh')\n",
    "    global stac_search_results\n",
    "    global df\n",
    "    \n",
    "    surfdetect_control['date_']=pd.to_datetime(surfdetect_control['date_'])\n",
    "    df=surfdetect_control.loc[(surfdetect_control['date_'] >= date_range[0]) & (surfdetect_control['date_'] <= date_range[1])]\n",
    "\n",
    "    df['nom']=df['nom'].apply(lambda x: x[20:])\n",
    "    df['groupe_id'] = np.nan\n",
    "    stac_search_results=stac_search(df['date_'].min(),df['date_'].max())\n",
    "\n",
    "    G = nx.Graph()\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        intersecting_ids = find_intersecting_id(row, df)\n",
    "        for id_ in intersecting_ids:\n",
    "            G.add_edge(row['surface_id_h3'], id_)\n",
    "\n",
    "    groupes = list(nx.connected_components(G))\n",
    "\n",
    "    for groupe_id, groupe in enumerate(groupes):\n",
    "        for id_ in groupe:\n",
    "            df.loc[df['surface_id_h3'] == id_, 'groupe_id'] = groupe_id\n",
    "\n",
    "    pluri_tile_surface,pluri_tile_number,pluri_detection_group,pluri_detection_surface=mesure_pluri_detection(df)\n",
    "    mono_tile_surface,mono_tile_number,mono_detection_group,mono_detection_surface=mesure_mono_detection(df)\n",
    "    tot_surf,nb_tot,tot_surf_tile=mesure_totale(df)\n",
    "\n",
    "    info_surfaces = pd.merge(mono_tile_number, mono_tile_surface, on='nom', how='outer')\n",
    "    info_surfaces = pd.merge(info_surfaces, pluri_tile_number, on='nom', how='outer')\n",
    "    info_surfaces = pd.merge(info_surfaces, pluri_tile_surface, on='nom', how='outer')\n",
    "\n",
    "    info_surfaces=info_surfaces.rename(columns={'nom':'Tile name','count_x':'Number of mono detection','surface':'Sum of mono detected area','count_y':'Number of pluri detection',0:'Sum of pluri detected area'})\n",
    "    info_surfaces=info_surfaces.round(2)\n",
    "\n",
    "    table = pn.widgets.Tabulator(info_surfaces, name=\"Informations à l'échelle des tuiles Sentinel-2\",header_align='center', show_index=False,\n",
    "                stylesheets=[stylesheet])\n",
    "    table.style.apply(highlight_max)\n",
    "#################################    \n",
    "    map = figure(width=800,title=\"Carte des surfaces brûlées estimées par tuiles pour les dates sélectionnées\",x_range=(162.5,169.5))\n",
    "\n",
    "    map.patches('x', 'y', source=nc,\n",
    "        fill_alpha=1, line_color=\"black\", line_width=0.2)    ## plot of new caledonia land\n",
    "\n",
    "    line=map.patches('x', 'y', source=tuile, ## plot of tiles limits\n",
    "            fill_alpha=0, line_color=\"black\", line_width=1)\n",
    "    \n",
    "    tt=pd.merge(centroid_tuile, tot_surf_tile, on='nom', how='left')\n",
    "\n",
    "    source_tt = ColumnDataSource(data={'x': tt['x'], 'y': tt['y'], 'surfaces': tt['0_y'], 'name': tt['nom']})\n",
    "    facteur_de_reduction = 0.1\n",
    "    sizes_reduites = [size * facteur_de_reduction for size in tt['0_y']]\n",
    "\n",
    "    source_tt.data['sizes'] = sizes_reduites\n",
    "\n",
    "    circles=map.circle('x', 'y', source=source_tt, size='sizes' ,\n",
    "            fill_alpha=1,fill_color=\"orange\", line_color=\"black\", line_width=1)\n",
    "\n",
    "    tooltip = HoverTool(renderers=[circles])  \n",
    "    tooltip.tooltips = [\n",
    "        ('Tuile', '@name'),\n",
    "        ('Surface', '@surfaces')  \n",
    "    ]\n",
    "    map.add_tools(tooltip)\n",
    "\n",
    "    return(table,map,nb_tot,tot_surf,mono_detection_group,pluri_detection_group,mono_detection_surface,pluri_detection_surface)\n",
    "\n",
    "############################\n",
    "\n",
    "def maj_graphic(date_range,choix):\n",
    "    global stac_search_results\n",
    "    global df\n",
    "\n",
    "    date_range = pd.date_range(start=df['date_'].min(), end=df['date_'].max())\n",
    "    full_date_series = pd.DataFrame(date_range.strftime('%Y-%m-%d'), columns=['date_'])\n",
    "    full_date_series['date_']=pd.to_datetime(full_date_series['date_'])\n",
    "\n",
    "    df_tiles = df.groupby(['date_', 'nom']).size().reset_index(name='nombre_occurrences')\n",
    "\n",
    "    df_tiles = df_tiles[df_tiles['nom'] == choix]\n",
    "    \n",
    "    df_tiles = pd.merge(full_date_series, df_tiles, on='date_', how='left')\n",
    "    df_tiles['nom'] = df_tiles['nom'].fillna(choix)\n",
    "\n",
    "    df_cloud_cover=stac_search_results[stac_search_results['nom'] == choix]\n",
    "    df_tot= pd.merge(df_tiles, df_cloud_cover, on='date_', how='left')\n",
    "\n",
    "    tile = hv.Bars(df_tot,  ('date_','Date'), ('nombre_occurrences','Nombre de détection')).opts(color='orange',tools=['hover']).opts(color='orange')\n",
    "    cc_fig=df_tot.hvplot(x='date_', y='Cloud_Cover', kind='scatter').opts(color='black', marker='s', size=30) \n",
    "\n",
    "    combined = (tile + cc_fig).cols(1)\n",
    "    date_formatter = '%Y-%m-%d' \n",
    "    combined.opts(\n",
    "        opts.Scatter(height=400, width=1800, xrotation=45, responsive=True,title='Evolution de la couverture nuageuse (%)',hooks=[apply_formatter],shared_axes=True),\n",
    "        opts.Bars(height=600, width=1800, xrotation=45, responsive=True,title=\"Nombre de détection par jour\",hooks=[apply_formatter],shared_axes=True),\n",
    "        opts.Layout(shared_axes=True))\n",
    "\n",
    "    image_elements = []\n",
    "    for _, row in df_cloud_cover.iterrows():\n",
    "        url = row['thumbnail_url']\n",
    "        response = requests.get(url)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        img_array = np.array(img)\n",
    "        image_elements.append(hv.RGB(img_array).opts(title=f\"Date: {row['date_'].date()}, Cloud: {row['Cloud_Cover']}%\"))\n",
    "\n",
    "    grid = hv.Layout(image_elements).opts(opts.RGB(width=500, height=500, xaxis=None, yaxis=None)).cols(3)\n",
    "    grid = hv.Layout(grid).opts(width=1200,height=600)\n",
    "\n",
    "    return combined,grid\n",
    "\n",
    "total_detection=pn.indicators.Number(name='Totale détection', value=0, format='{value}',colors=[(0,'blue')])\n",
    "surface_total=pn.indicators.Number(name='Surface totale estimée (ha)', value=0, format='{value}',colors=[(0,'blue')])\n",
    "mono_detection_group=pn.indicators.Number(name='Nombre de Mono détection', value=0, format='{value}',colors=[(0,'red')])\n",
    "pluri_detection_group=pn.indicators.Number(name='Nombre de Pluri détections', value=0, format='{value}',colors=[(0,'green')])\n",
    "mono_detection_surface=pn.indicators.Number(name='Surface (ha) Mono détection', value=0, format='{value}',colors=[(0,'red')])\n",
    "pluri_detection_surface=pn.indicators.Number(name='Surface (ha) Pluri détections', value=0, format='{value}',colors=[(0,'green')])\n",
    "\n",
    "table_map_container = pn.Row()  \n",
    "graphic_container = pn.Column() \n",
    "interface_1_container = pn.Column()\n",
    "\n",
    "def update_interface_1(event):\n",
    "    global table_map_container\n",
    "    \n",
    "    table, map, nb_tot, tot_surf, mono_nb, pluri_nb, mono_surf, pluri_surf = maj_table(datetime_range_picker.value) \n",
    "    mono_detection_group.value = mono_nb\n",
    "    pluri_detection_group.value = pluri_nb\n",
    "    \n",
    "    mono_detection_surface.value = mono_surf\n",
    "    pluri_detection_surface.value = pluri_surf\n",
    "\n",
    "    total_detection.value = nb_tot\n",
    "    surface_total.value = tot_surf\n",
    "    \n",
    "    table_map_container[:] = [table, map]\n",
    "    interface_1_container[:] = [table_map_container, tile_bouton]\n",
    "    \n",
    "    if interface_1_container not in main:\n",
    "        main.append(interface_1_container)\n",
    "    if graphic_container not in main:\n",
    "        main.append(graphic_container)\n",
    "\n",
    "def update_interface_2(event):\n",
    "    global graphic_container\n",
    "    \n",
    "    choix = event.new\n",
    "    fig, image = maj_graphic(datetime_range_picker.value, tile_bouton.value)\n",
    "    graphic_container[:] = [fig, image]    \n",
    "\n",
    "datetime_range_picker = pn.widgets.DatetimeRangePicker(name='Select your Date Range', start=dt.datetime(2023, 1, 1), end=dt.datetime(2024, 12, 31))\n",
    "datetime_range_picker.param.watch(update_interface_1, 'value')\n",
    "\n",
    "tile_bouton.param.watch(update_interface_2, 'value')\n",
    "\n",
    "sidebar = pn.Column(datetime_range_picker,\"# Indicateurs Globaux\", total_detection,surface_total,mono_detection_group, mono_detection_surface,pluri_detection_group,pluri_detection_surface)\n",
    "main = pn.Column(\"## Step 1 : Selectionner un intervalle de date pour voir les données et indicateurs globaux. \\n ## Step 2 : Choisir une ZAE à observer\") \n",
    "\n",
    "template =pn.template.FastListTemplate(\n",
    "    site=\"Panel\", header_background ='#f89424',title=\"Dashboard Contrôle des surfaces brûlées en sortie en chaîne\",logo=\"https://neotech.nc/wp-content/uploads/2023/10/logo_oeil_quadri-254x300.jpeg.webp\",sidebar=[sidebar],main=[main])\n",
    "\n",
    "template.servable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## panel serve 03_Dashboard_controle_V2.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
