{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, LineString, shape, mapping\n",
    "import networkx as nx\n",
    "import datetime as dt\n",
    "from pystac_client import Client\n",
    "from holoviews import opts\n",
    "from intake import open_catalog\n",
    "import panel as pn\n",
    "import numpy as np\n",
    "from bokeh.models import HoverTool, LogColorMapper, ColumnDataSource, DatetimeTickFormatter\n",
    "from bokeh.plotting import figure\n",
    "from odc.stac import configure_rio, stac_load\n",
    "import holoviews as hv\n",
    "from bokeh.models.formatters import DatetimeTickFormatter\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import hvplot.pandas \n",
    "from functools import reduce\n",
    "\n",
    "load_dotenv()\n",
    "## panel serve 03_Dashboard_controle_V2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catfeux = open_catalog(f'{os.getenv(\"PROJECT_PATH\")}Fire_Detection_Data_Quality.yaml')\n",
    "table_source='vue_sentinel_brute_2023'\n",
    "table_viirs_snpp='incendie_viirs_snpp_maj'\n",
    "table_viirs_noaa='incendie_viirs_noaa20_maj'\n",
    "catalog_stac=\"https://earth-search.aws.element84.com/v1\"\n",
    "\n",
    "tile_sentinel=catfeux.tile_sentinel2_line_UTM.read()\n",
    "tile_sentinel=tile_sentinel.to_crs(epsg=4326)\n",
    "\n",
    "nc_limits=catfeux.nc_limits.read()\n",
    "nc_limits=nc_limits.to_crs(epsg=4326)\n",
    "\n",
    "def linestring_to_polygon(gdf):\n",
    "    polygons = []\n",
    "    \n",
    "    for index, row in gdf.iterrows():\n",
    "        all_coords = mapping(row['geometry'])['coordinates']\n",
    "        lats = [x[1] for x in all_coords]\n",
    "        lons = [x[0] for x in all_coords]\n",
    "        \n",
    "        polyg = Polygon(zip(lons, lats))\n",
    "        polygons.append(polyg)\n",
    "    new_gdf = gpd.GeoDataFrame(geometry=polygons, crs=gdf.crs)\n",
    "    \n",
    "    return new_gdf\n",
    "\n",
    "test = linestring_to_polygon(tile_sentinel)\n",
    "tile_sentinel['geometry']=test['geometry']\n",
    "tile_sentinel['Name']='L2A_T'+tile_sentinel['Name']\n",
    "\n",
    "centroid = (tile_sentinel.centroid)\n",
    "centroid_tuile = pd.DataFrame(centroid)\n",
    "\n",
    "centroid_tuile['x']=centroid.x\n",
    "centroid_tuile['y']=centroid.y\n",
    "centroid_tuile['nom']=tile_sentinel['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPolyCoords(row, geom, coord_type):\n",
    "    \"\"\"Returns the coordinates ('x' or 'y') of edges of a Polygon exterior\"\"\"\n",
    "    exterior = row[geom].exterior\n",
    "\n",
    "    if coord_type == 'x':\n",
    "        return list( exterior.coords.xy[0] )\n",
    "    elif coord_type == 'y':\n",
    "        return list( exterior.coords.xy[1] )\n",
    "\n",
    "tile_sentinel['x'] = tile_sentinel.apply(getPolyCoords, geom='geometry', coord_type='x', axis=1)\n",
    "tile_sentinel['y'] = tile_sentinel.apply(getPolyCoords, geom='geometry', coord_type='y', axis=1)\n",
    "\n",
    "m_df = tile_sentinel.drop('geometry', axis=1).copy()\n",
    "tuile = ColumnDataSource(m_df)\n",
    "\n",
    "nc_limits=nc_limits.explode()\n",
    "nc_limits['x'] = nc_limits.apply(getPolyCoords, geom='shape', coord_type='x', axis=1)\n",
    "nc_limits['y'] = nc_limits.apply(getPolyCoords, geom='shape', coord_type='y', axis=1)\n",
    "\n",
    "m_df_2 = nc_limits.drop('shape', axis=1).copy()\n",
    "nc = ColumnDataSource(m_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_intersecting_id(row, gdf):\n",
    "\n",
    "    possible_matches_index = list(gdf.sindex.intersection(row['geometry'].bounds))\n",
    "    possible_matches = gdf.iloc[possible_matches_index]\n",
    "    precise_matches = possible_matches[possible_matches.geometry.intersects(row['geometry'])]\n",
    "    intersecting_ids = precise_matches['surface_id_h3'].tolist()\n",
    "    intersecting_ids = [id_ for id_ in intersecting_ids if id_ != row['surface_id_h3']]\n",
    "    return intersecting_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mesure_totale(df):\n",
    "    \"\"\"\n",
    "    tot_surf : total number of detected area (ha)\n",
    "    tot_surf_tile: total sum of detected area per tile (ha)\n",
    "    \"\"\"\n",
    "    tot_nb = len(df)\n",
    "    tot_surf = df.dissolve().area.sum() / 10000\n",
    "    tot_surf_tile = df.dissolve(by='nom').area / 10000\n",
    "    tot_surf_tile = tot_surf_tile.reset_index()\n",
    "    \n",
    "    return(tot_surf,tot_nb,tot_surf_tile)\n",
    "\n",
    "def mesure_pluri_detection(df):\n",
    "    \"\"\"\n",
    "    pluri_detection_surface : number of pluri detected detected area (ha)\n",
    "    pluri_detection_group: number of group\n",
    "    pluri_tile_number : number of detection per tile\n",
    "    pluri_tile_surface : sum of detected area per tile (ha)\n",
    "    \"\"\"\n",
    "    pluri_detection_list = df[df['groupe_id'].notna()]\n",
    "    pluri_detection_surface = pluri_detection_list.dissolve().area.sum() / 10000\n",
    "    pluri_detection_group = pluri_detection_list['groupe_id'].nunique()\n",
    "    pluri_tile_number = pluri_detection_list['nom'].value_counts().reset_index()\n",
    "    pluri_tile_surface = pluri_detection_list.dissolve(by='nom').area / 10000\n",
    "    pluri_tile_surface = pluri_tile_surface.reset_index()\n",
    "\n",
    "    return(pluri_tile_surface,pluri_tile_number,pluri_detection_group,pluri_detection_surface)\n",
    "\n",
    "def mesure_mono_detection(df):\n",
    "    \"\"\"\n",
    "    mono_detection_surface : number of mono detected detected area (ha)\n",
    "    mono_detection_group: number of group\n",
    "    mono_tile_number : number of detection per tile\n",
    "    mono_tile_surface : sum of detected area per tile (ha)\n",
    "    \"\"\"\n",
    "    mono_detection_list=df[df['groupe_id'].isna()]\n",
    "    mono_detection_surface=mono_detection_list['surface'].sum() \n",
    "    mono_detection_group=mono_detection_list['groupe_id'].isna().sum() \n",
    "    mono_tile_number = pd.DataFrame(mono_detection_list[\"nom\"].value_counts()) \n",
    "    mono_tile_surface = mono_detection_list.groupby('nom')['surface'].sum().reset_index() \n",
    "    \n",
    "    return(mono_tile_surface,mono_tile_number,mono_detection_group,mono_detection_surface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_multiple_date_formats(date_str, formats):\n",
    "    for fmt in formats:\n",
    "        try:\n",
    "            return pd.to_datetime(date_str, format=fmt)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return pd.NaT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stac_search(date_start,date_end):\n",
    "\n",
    "    catalog = Client.open(catalog_stac)\n",
    "    query = catalog.search(\n",
    "        collections=[\"sentinel-2-l2a\"],datetime=(date_start).strftime('%Y-%m-%d')+'/'+(date_end).strftime('%Y-%m-%d'), bbox=[163.362, -22.76, 168.223, -19.479],       \n",
    "        fields={\"include\": [\"properties.grid:code\", \"properties.datetime\", \"properties.eo:cloud_cover\", \"assets.thumbnail.href\"], \"exclude\": []})\n",
    "\n",
    "    items = list(query.items())\n",
    "    stac_json = query.item_collection_as_dict()\n",
    "\n",
    "    gdf = gpd.GeoDataFrame.from_features(stac_json, \"epsg:4326\")\n",
    "    thumbnails = [item.assets['thumbnail'].href for item in items]\n",
    "\n",
    "    df = gdf.rename(columns={\n",
    "        'grid:code': 'nom',\n",
    "        'datetime': 'date_',\n",
    "        'eo:cloud_cover': 'Cloud_Cover',\n",
    "        'thumbnail.href': 'thumbnail'\n",
    "    })\n",
    "\n",
    "    df['nom'] = [x[5:] for x in df['nom']]\n",
    "    df['nom']='L2A_T'+df['nom'] \n",
    "\n",
    "    df=df.reset_index(drop=True)\n",
    "    date_formats = ['%Y-%m-%dT%H:%M:%SZ', '%Y-%m-%d %H:%M:%S.%f%z','%Y-%m-%dT%H:%M:%S.%fZ']\n",
    "    df['date_'] = df['date_'].apply(try_multiple_date_formats, formats=date_formats)\n",
    "    df['date_'] = df['date_'].dt.strftime('%Y-%m-%d')\n",
    "    df['date_'] = pd.to_datetime(df['date_'])\n",
    "    \n",
    "    df['thumbnail_url'] = thumbnails\n",
    "    df = df.sort_values(by='date_', ascending=True)\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_table(date_range):\n",
    "\n",
    "    sql = f\"\"\"SELECT *\n",
    "    FROM feux_cq.{table_source} si\n",
    "    WHERE si.date_ >= '{pd.to_datetime(date_range[0]).strftime('%Y-%m-%d')}' AND si.date_ <= '{pd.to_datetime(date_range[1]).strftime('%Y-%m-%d')}'\n",
    "    \"\"\"\n",
    "    dataCatalog = getattr(catfeux, table_source)(sql_expr=sql)\n",
    "    df = dataCatalog.read()\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df,full_date_series,name,choix):\n",
    "    df_tiles = df.groupby(['date_', 'nom']).size().reset_index(name=name)\n",
    "    df_tiles = df_tiles[df_tiles['nom'] == choix]\n",
    "\n",
    "    df_tiles['date_'] = df_tiles['date_'].dt.strftime('%Y-%m-%d')\n",
    "    df_tiles['date_']=pd.to_datetime(df_tiles['date_'])\n",
    "\n",
    "    df_tiles = pd.merge(full_date_series, df_tiles, on='date_', how='left')\n",
    "    df_tiles['nom'] = df_tiles['nom'].fillna(choix)\n",
    "\n",
    "    return(df_tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viirs_data(data,stl2_poly):\n",
    "    \n",
    "    dataCatalog = getattr(catfeux, data)\n",
    "    df = dataCatalog.read()\n",
    "    df=df.to_crs(epsg=4326)\n",
    "    df = gpd.sjoin(stl2_poly, df, how='inner')\n",
    "    df['date_']=pd.to_datetime(df['BegDate'])\n",
    "    df['nom']=df['Name'] \n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Start creation of dashboard\n",
    "\n",
    "pn.extension()\n",
    "pn.extension('tabulator')\n",
    "\n",
    "stylesheet = \"\"\"\n",
    ".tabulator-cell {\n",
    "    font-size: 20px;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "custom_style = {\n",
    "    'background': '#f89424',\n",
    "    'border': '1px solid black',\n",
    "    'padding': '10px',\n",
    "    'box-shadow': '5px 5px 5px #bcbcbc'\n",
    "}\n",
    "    \n",
    "def highlight_max(s):\n",
    "    '''\n",
    "    highlight the maximum in a Series yellow.\n",
    "    '''\n",
    "    is_max = s == s.max()\n",
    "    return ['background-color: f89424' if v else '' for v in is_max]\n",
    "\n",
    "tile_bouton = pn.widgets.RadioButtonGroup(options=['L2A_T58KCC','L2A_T58KCD','L2A_T58KDB','L2A_T58KDC','L2A_T58KEA','L2A_T58KEB','L2A_T58KEC',\n",
    "            'L2A_T58KFA','L2A_T58KFB','L2A_T58KFC','L2A_T58KGA','L2A_T58KGB','L2A_T58KGC','L2A_T58KGV','L2A_T58KHB'],align='center',stylesheets=[stylesheet],\n",
    "            button_type='warning',button_style='outline',name='Choose a tile')\n",
    "\n",
    "### PAGE 1 #########\n",
    "############ table\n",
    "\n",
    "def maj_table(date_range,table_source):\n",
    "    hv.extension('bokeh')\n",
    "\n",
    "    global stac_search_results, df\n",
    "    \n",
    "    df=read_table(date_range)\n",
    "\n",
    "    df['nom']=df['nom'].apply(lambda x: x[20:])\n",
    "    df['groupe_id'] = np.nan\n",
    "\n",
    "    stac_search_results=stac_search(df['date_'].min(),df['date_'].max())\n",
    "    df['date_'] = pd.to_datetime(df['date_'])\n",
    "\n",
    "    G = nx.Graph()\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        intersecting_ids = find_intersecting_id(row, df)\n",
    "        for id_ in intersecting_ids:\n",
    "            G.add_edge(row['surface_id_h3'], id_)\n",
    "\n",
    "    groupes = list(nx.connected_components(G))\n",
    "\n",
    "    for groupe_id, groupe in enumerate(groupes):\n",
    "        for id_ in groupe:\n",
    "            df.loc[df['surface_id_h3'] == id_, 'groupe_id'] = groupe_id\n",
    "\n",
    "    pluri_tile_surface,pluri_tile_number,pluri_detection_group,pluri_detection_surface=mesure_pluri_detection(df)\n",
    "    mono_tile_surface,mono_tile_number,mono_detection_group,mono_detection_surface=mesure_mono_detection(df)\n",
    "    tot_surf,nb_tot,tot_surf_tile=mesure_totale(df)\n",
    "\n",
    "    dataframes = [mono_tile_number, mono_tile_surface, pluri_tile_number, pluri_tile_surface]\n",
    "    info_surfaces = reduce(lambda left, right: pd.merge(left, right, on='nom', how='outer'), dataframes)\n",
    "\n",
    "    info_surfaces=info_surfaces.rename(columns={'nom':'Tile name','count_x':'Number of mono detection','surface':'Sum of mono detected area','count_y':'Number of pluri detection',0:'Sum of pluri detected area'})\n",
    "    info_surfaces=info_surfaces.round(2)\n",
    "\n",
    "    table = pn.widgets.Tabulator(info_surfaces, name=\"Informations à l'échelle des tuiles Sentinel-2\",header_align='center', show_index=False,\n",
    "                stylesheets=[stylesheet])\n",
    "    table.style.apply(highlight_max)\n",
    "\n",
    "#################################    \n",
    "\n",
    "    map = figure(width=800,title=\"Carte des surfaces brûlées estimées par tuiles pour les dates sélectionnées\",x_range=(162.5,169.5))\n",
    "\n",
    "    map.patches('x', 'y', source=nc,\n",
    "        fill_alpha=1, line_color=\"black\", line_width=0.2)    ## plot of new caledonia land\n",
    "\n",
    "    line=map.patches('x', 'y', source=tuile, ## plot of tiles limits\n",
    "            fill_alpha=0, line_color=\"black\", line_width=1)\n",
    "    \n",
    "    tt=pd.merge(centroid_tuile, tot_surf_tile, on='nom', how='left')\n",
    "\n",
    "    source_tt = ColumnDataSource(data={'x': tt['x'], 'y': tt['y'], 'surfaces': tt['0_y'], 'name': tt['nom']})\n",
    "    facteur_de_reduction = 0.08\n",
    "    minimum_size = 5  \n",
    "\n",
    "    sizes = np.log10(tt['0_y'] + 1) * facteur_de_reduction  \n",
    "    sizes = (sizes / sizes.max()) * 50 + minimum_size  \n",
    "    source_tt.data['sizes'] = sizes\n",
    "\n",
    "    circles=map.circle('x', 'y', source=source_tt, size='sizes' ,\n",
    "            fill_alpha=1,fill_color=\"orange\", line_color=\"black\", line_width=1)\n",
    "\n",
    "    tooltip = HoverTool(renderers=[circles])  \n",
    "    tooltip.tooltips = [\n",
    "        ('Tuile', '@name'),\n",
    "        ('Surface', '@surfaces')  \n",
    "    ]\n",
    "    map.add_tools(tooltip)\n",
    "\n",
    "    return(table,map,nb_tot,tot_surf,mono_detection_group,pluri_detection_group,mono_detection_surface,pluri_detection_surface)\n",
    "\n",
    "############################\n",
    "\n",
    "def maj_graphic(date_range,choix):\n",
    "    global stac_search_results, df\n",
    "\n",
    "    viirs_snpp=viirs_data(table_viirs_snpp,tile_sentinel)\n",
    "    viirs_noaa=viirs_data(table_viirs_noaa,tile_sentinel)\n",
    "\n",
    "    viirs_snpp=viirs_snpp[(viirs_snpp['date_'] >= pd.to_datetime(date_range[0]).strftime('%Y-%m-%d')) & (viirs_snpp['date_']<=pd.to_datetime(date_range[1]).strftime('%Y-%m-%d'))]\n",
    "    viirs_noaa=viirs_noaa[(viirs_noaa['date_'] >= pd.to_datetime(date_range[0]).strftime('%Y-%m-%d')) & (viirs_noaa['date_']<=pd.to_datetime(date_range[1]).strftime('%Y-%m-%d'))]\n",
    "    print(viirs_noaa)\n",
    "\n",
    "    date_range = pd.date_range(start=df['date_'].min(), end=df['date_'].max())\n",
    "    full_date_series = pd.DataFrame(date_range.strftime('%Y-%m-%d'), columns=['date_'])\n",
    "    full_date_series['date_']=pd.to_datetime(full_date_series['date_'])\n",
    "    \n",
    "    df_tiles=prepare_data(df,full_date_series,\"Sentinel-2\",choix)\n",
    "    snpp=prepare_data(viirs_snpp,full_date_series,\"Snpp\",choix)\n",
    "    noaa=prepare_data(viirs_noaa,full_date_series,\"Noaa-20\",choix)\n",
    "\n",
    "    df_cloud_cover=stac_search_results[stac_search_results['nom'] == choix]\n",
    "\n",
    "    dataframes = [df_tiles, df_cloud_cover, noaa, snpp]\n",
    "    df_tot = reduce(lambda left, right: pd.merge(left, right, on='date_', how='left', suffixes=('', '_y')), dataframes)\n",
    "    df_tot = df_tot.loc[:, ~df_tot.columns.str.endswith('_y')]\n",
    "\n",
    "    bar_plot=df_tot.hvplot(x='date_',y=['Sentinel-2', 'Snpp','Noaa-20'], kind='bar', width=800, height=400, title=\"Nombre de détection par jour\", legend='top_left').opts(multi_level=False,\n",
    "                                                                                                                                            xlabel='Date')\n",
    "    cc_fig=df_tot.hvplot(x='date_', y='Cloud_Cover', kind='scatter').opts(color='black', marker='s', size=30) \n",
    "\n",
    "    combined = hv.Layout([bar_plot, cc_fig]).cols(1)\n",
    "    combined.opts(\n",
    "        opts.Scatter(height=400, width=1800, xrotation=45, responsive=True,title='Evolution de la couverture nuageuse (%)',shared_axes=True),\n",
    "        opts.Bars(height=600, width=1800, xrotation=45, responsive=True,title=\"Nombre de détection par jour\",shared_axes=True, show_legend=True),\n",
    "        opts.Layout(shared_axes=True))\n",
    "\n",
    "    image_elements = []\n",
    "    for _, row in df_cloud_cover.iterrows():\n",
    "        url = row['thumbnail_url']\n",
    "        response = requests.get(url)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        img_array = np.array(img)\n",
    "        image_elements.append(hv.RGB(img_array).opts(title=f\"Date: {row['date_'].date()}, Cloud: {row['Cloud_Cover']}%\"))\n",
    "\n",
    "    grid = hv.Layout(image_elements).opts(opts.RGB(width=500, height=500, xaxis=None, yaxis=None)).cols(3)\n",
    "    grid = hv.Layout(grid).opts(width=1200,height=600)\n",
    "\n",
    "    return combined,grid\n",
    "\n",
    "total_detection=pn.indicators.Number(name='Totale détection', value=0, format='{value}',colors=[(0,'blue')])\n",
    "surface_total=pn.indicators.Number(name='Surface totale estimée (ha)', value=0, format='{value}',colors=[(0,'blue')])\n",
    "mono_detection_group=pn.indicators.Number(name='Nombre de Mono détection', value=0, format='{value}',colors=[(0,'red')])\n",
    "pluri_detection_group=pn.indicators.Number(name='Nombre de Pluri détections', value=0, format='{value}',colors=[(0,'green')])\n",
    "mono_detection_surface=pn.indicators.Number(name='Surface (ha) Mono détection', value=0, format='{value}',colors=[(0,'red')])\n",
    "pluri_detection_surface=pn.indicators.Number(name='Surface (ha) Pluri détections', value=0, format='{value}',colors=[(0,'green')])\n",
    "\n",
    "table_map_container = pn.Row()  \n",
    "graphic_container = pn.Column() \n",
    "interface_1_container = pn.Column()\n",
    "\n",
    "def update_interface_1(event):\n",
    "    global table_map_container\n",
    "    \n",
    "    table, map, nb_tot, tot_surf, mono_nb, pluri_nb, mono_surf, pluri_surf = maj_table(datetime_range_picker.value,table_source) \n",
    "    mono_detection_group.value = mono_nb\n",
    "    pluri_detection_group.value = pluri_nb\n",
    "    \n",
    "    mono_detection_surface.value = mono_surf\n",
    "    pluri_detection_surface.value = pluri_surf\n",
    "\n",
    "    total_detection.value = nb_tot\n",
    "    surface_total.value = tot_surf\n",
    "    \n",
    "    table_map_container[:] = [table, map]\n",
    "    interface_1_container[:] = [table_map_container, tile_bouton]\n",
    "    \n",
    "    if interface_1_container not in main:\n",
    "        main.append(interface_1_container)\n",
    "    if graphic_container not in main:\n",
    "        main.append(graphic_container)\n",
    "\n",
    "def update_interface_2(event):\n",
    "    global graphic_container\n",
    "    \n",
    "    choix = event.new\n",
    "    fig, image = maj_graphic(datetime_range_picker.value, tile_bouton.value)\n",
    "    graphic_container[:] = [fig, image]    \n",
    "\n",
    "datetime_range_picker = pn.widgets.DatetimeRangePicker(name='Select your Date Range', start=dt.datetime(2023, 1, 1), end=dt.datetime(2024, 12, 31))\n",
    "datetime_range_picker.param.watch(update_interface_1, 'value')\n",
    "\n",
    "tile_bouton.param.watch(update_interface_2, 'value')\n",
    "\n",
    "sidebar = pn.Column(datetime_range_picker,\"# Indicateurs Globaux\", total_detection,surface_total,mono_detection_group, mono_detection_surface,pluri_detection_group,pluri_detection_surface)\n",
    "main = pn.Column(\"## Step 1 : Selectionner un intervalle de date pour voir les données et indicateurs globaux. \\n ## Step 2 : Choisir une ZAE à observer\") \n",
    "\n",
    "template =pn.template.FastListTemplate(\n",
    "    site=\"Panel\", header_background ='#f89424',title=\"Dashboard Contrôle des surfaces brûlées en sortie en chaîne\",logo=\"https://neotech.nc/wp-content/uploads/2023/10/logo_oeil_quadri-254x300.jpeg.webp\",sidebar=[sidebar],main=[main])\n",
    "\n",
    "template.servable()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
