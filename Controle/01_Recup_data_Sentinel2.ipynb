{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .env\n"
     ]
    }
   ],
   "source": [
    "%%writefile \".env\"\n",
    "\n",
    "PROJECT_ID=\"feux_cq\"\n",
    "\n",
    "COMMUN_PATH = \"C:/\"\n",
    "PATH_INFOCENTRE_APP = ${COMMUN_PATH}Informatique/SIG/Application/Jupyterhub/\n",
    "PATH_ETUDE = ${COMMUN_PATH}Informatique/SIG/Donnees/Oeil/Traitement_Donnees/SURFACES_BRULEES_SENTINEL/2022/220502_PreparationFeu2020/\n",
    "PROJECT_PATH =${COMMUN_PATH}Users/oriane.bruyere/Documents/Projet_feux/Script/Step1_detection_error/\n",
    "DATA_CATALOG_DIR = ${PATH_INFOCENTRE_APP}projets/catalogFiles/ \n",
    "DATA_OUTPUT_DIR = ${PROJECT_PATH}output/\n",
    "SIG_DATA_PATH = ${COMMUN_PATH}Informatique/SIG/Donnees/\n",
    "DB_USER=\"jfnguyenvansoc\"\n",
    "DB_PWD=\"oeil\"\n",
    "DB_HOST=\"172.20.12.13\"\n",
    "DB_PORT=5432\n",
    "\n",
    "DB_WORKSPACE=\"oeil_traitement\"\n",
    "DB_REF=\"oeil_reference\"\n",
    "DB_EXT=\"data_externe\"\n",
    "DB_SCHEMA = \"feux_cq\"\n",
    "DB_SCHEMA_REF = \"feux\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get missing burned areas files from INSIGHT server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "from os import listdir\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import fiona\n",
    "from sqlalchemy import create_engine\n",
    "import h3\n",
    "from shapely.geometry import MultiPolygon\n",
    "from datetime import datetime\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open gpkg and add data to POSTGIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEMP ='A:/FEUX_INSIGHT/2024/'\n",
    "\n",
    "date_start=datetime(2024,1,1)\n",
    "date_end=datetime(2024,5,31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données fusionnées à partir des GeoPackages :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oriane.bruyere\\AppData\\Local\\Temp\\ipykernel_8600\\2024689450.py:28: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  gdf = pd.concat(gdf_list, ignore_index=True, sort=False)\n"
     ]
    }
   ],
   "source": [
    "fichiers_geopackages = [f for f in os.listdir(DATA_TEMP) if f.endswith('.gpkg')]\n",
    "gdf_list = []\n",
    "\n",
    "for fichier_geopackage in fichiers_geopackages:\n",
    "    chemin_geopackage = os.path.join(DATA_TEMP, fichier_geopackage)\n",
    "    couches = fiona.listlayers(chemin_geopackage)\n",
    "\n",
    "    for couche in couches:\n",
    "        gdf_couches = gpd.read_file(chemin_geopackage, layer=couche, driver='GPKG')\n",
    "        \n",
    "        if 'date_' in gdf_couches.columns:\n",
    "            gdf_couches['date_']=pd.to_datetime(gdf_couches['date_'])\n",
    "            gdf_couches['date_']=gdf_couches['date_'].dt.date\n",
    "            gdf_couches['datetexte'] = gdf_couches['date_texte'].apply(lambda x: x[:-11] if len(x) > 8 else x)\n",
    "\n",
    "        elif 'date_texte' or 'date' in gdf_couches.columns:\n",
    "            gdf_couches.rename(columns={'date_texte': 'date_'}, inplace=True)\n",
    "            gdf_couches.rename(columns={'date': 'date_'}, inplace=True)\n",
    "            \n",
    "            gdf_couches['datetexte'] = gdf_couches['date_'].apply(lambda x: x[:-11] if len(x) > 8 else x)\n",
    "            gdf_couches['date_']=pd.to_datetime(gdf_couches['datetexte'])\n",
    "            gdf_couches['date_']=gdf_couches['date_'].dt.date\n",
    "\n",
    "    \n",
    "        gdf_couches['nom'] = gdf_couches['nom'].apply(lambda x: x[:19] + x[30:] if len(x) > 30 else x)\n",
    "        gdf_list.append(gdf_couches)\n",
    "\n",
    "gdf = pd.concat(gdf_list, ignore_index=True, sort=False)\n",
    "gdf=gdf.reset_index(drop=True)\n",
    "\n",
    "### filtre sur le data set\n",
    "gdf['date_']=pd.to_datetime(gdf['date_'])\n",
    "gdf=gdf.loc[(gdf['date_'] >= date_start) & (gdf['date_'] <= date_end)]\n",
    "gdf=gdf.reset_index(drop=True)\n",
    "\n",
    "print(\"Données fusionnées à partir des GeoPackages :\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertir les surfaces detectees en type MULTIPOLYGONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date_                             nom           province    commune  \\\n",
      "0    2024-01-03  SENTINEL2A_20240103_L2A_T58KFC  Province des Iles      OUVEA   \n",
      "1    2024-01-03  SENTINEL2A_20240103_L2A_T58KFC  Province des Iles      OUVEA   \n",
      "2    2024-01-03  SENTINEL2A_20240103_L2A_T58KEC      Province Nord      TOUHO   \n",
      "3    2024-01-03  SENTINEL2A_20240103_L2A_T58KEC      Province Nord      TOUHO   \n",
      "4    2024-01-03  SENTINEL2A_20240103_L2A_T58KEC      Province Nord      TOUHO   \n",
      "...         ...                             ...                ...        ...   \n",
      "8727 2024-05-30  SENTINEL2B_20240530_L2A_T58KDB      Province Nord        VOH   \n",
      "8728 2024-05-30  SENTINEL2B_20240530_L2A_T58KDB      Province Nord  POUEMBOUT   \n",
      "8729 2024-05-30  SENTINEL2B_20240530_L2A_T58KDB      Province Nord  POUEMBOUT   \n",
      "8730 2024-05-30  SENTINEL2B_20240530_L2A_T58KDB      Province Nord  POUEMBOUT   \n",
      "8731 2024-05-30  SENTINEL2B_20240530_L2A_T58KDB      Province Nord  POUEMBOUT   \n",
      "\n",
      "       surface       x       y                             cuirasse  \\\n",
      "0     1.050176  456151  392850                                 None   \n",
      "1     1.160224  450723  389037                                 None   \n",
      "2     2.011472  321161  379784                                 None   \n",
      "3     1.310942  321453  376332                                 None   \n",
      "4     1.080766  313557  371406                                 None   \n",
      "...        ...     ...     ...                                  ...   \n",
      "8727  3.772377  264844  350538  Cuirasses disloquées et démantelées   \n",
      "8728  1.370843  290410  332240                                 None   \n",
      "8729  3.912406  290329  332075                                 None   \n",
      "8730  1.220750  290011  331819                                 None   \n",
      "8731  4.022471  289861  331699  Cuirasses disloquées et démantelées   \n",
      "\n",
      "      cuira_area bdtopo  bdtop_area  \\\n",
      "0            NaN   None         NaN   \n",
      "1            NaN   None         NaN   \n",
      "2            NaN   None         NaN   \n",
      "3            NaN   None         NaN   \n",
      "4            NaN   None         NaN   \n",
      "...          ...    ...         ...   \n",
      "8727        10.0   None         NaN   \n",
      "8728         NaN   None         NaN   \n",
      "8729         NaN   None         NaN   \n",
      "8730         NaN   None         NaN   \n",
      "8731         4.0   None         NaN   \n",
      "\n",
      "                                               geometry datetexte  \n",
      "0     MULTIPOLYGON (((456115.045 392979.061, 456115....  20240103  \n",
      "1     MULTIPOLYGON (((450747.747 389126.202, 450747....  20240103  \n",
      "2     MULTIPOLYGON (((321127.931 379919.240, 321127....  20240103  \n",
      "3     MULTIPOLYGON (((321440.319 376409.878, 321440....  20240103  \n",
      "4     MULTIPOLYGON (((313648.463 371518.516, 313648....  20240103  \n",
      "...                                                 ...       ...  \n",
      "8727  MULTIPOLYGON (((264744.386 350667.891, 264744....  20240530  \n",
      "8728  MULTIPOLYGON (((290470.733 332306.817, 290470....  20240530  \n",
      "8729  MULTIPOLYGON (((290171.479 332174.858, 290171....  20240530  \n",
      "8730  MULTIPOLYGON (((289943.334 331873.299, 289943....  20240530  \n",
      "8731  MULTIPOLYGON (((289733.338 331861.952, 289733....  20240530  \n",
      "\n",
      "[8732 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# Vérifier si la géométrie est de type Polygon\n",
    "if gdf['geometry'].geom_type[0] == 'Polygon':\n",
    "    gdf['geometry'] = gdf['geometry'].apply(lambda poly: MultiPolygon([poly]))\n",
    "\n",
    "    print(gdf)\n",
    "else:\n",
    "    print(\"La géométrie n'est pas de type Polygon.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajouter une identifiant H3 et créer un identifiant unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "H3_res = 15\n",
    "def geo_to_h3(row):\n",
    "  return h3.geo_to_h3(row.lat,row.lon,resolution = H3_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oriane.bruyere\\AppData\\Local\\Temp\\ipykernel_8600\\1044648674.py:4: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf['centroides']=gdf['geometry'].centroid\n",
      "C:\\Users\\oriane.bruyere\\AppData\\Local\\Temp\\ipykernel_8600\\1044648674.py:12: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  gdf['surface_id_h3'][i]=str(gdf['nom'][i][-10:])+\"_\"+str(gdf['datetexte'][i])+\"_\"+str(gdf['h3_id'][i])\n",
      "C:\\Users\\oriane.bruyere\\AppData\\Local\\Temp\\ipykernel_8600\\1044648674.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gdf['surface_id_h3'][i]=str(gdf['nom'][i][-10:])+\"_\"+str(gdf['datetexte'][i])+\"_\"+str(gdf['h3_id'][i])\n",
      "C:\\Users\\oriane.bruyere\\AppData\\Local\\Temp\\ipykernel_8600\\1044648674.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'L2A_T58KFC_20240103_8f9f5235012c19e' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  gdf['surface_id_h3'][i]=str(gdf['nom'][i][-10:])+\"_\"+str(gdf['datetexte'][i])+\"_\"+str(gdf['h3_id'][i])\n"
     ]
    }
   ],
   "source": [
    "gdf=gdf.to_crs(4326) ## change coordinates to WGS84\n",
    "gdf=gdf.set_crs(\"EPSG:4326\")\n",
    "\n",
    "gdf['centroides']=gdf['geometry'].centroid\n",
    "gdf['lon'] = gdf.centroides.x\n",
    "gdf['lat'] = gdf.centroides.y\n",
    "\n",
    "gdf['h3_id'] = gdf.apply(geo_to_h3,axis=1)\n",
    "\n",
    "gdf['surface_id_h3']=0\n",
    "for i in range(len(gdf)):\n",
    "  gdf['surface_id_h3'][i]=str(gdf['nom'][i][-10:])+\"_\"+str(gdf['datetexte'][i])+\"_\"+str(gdf['h3_id'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création de la base de donnée dans POSTGIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(gdf.copy(), crs=gdf.crs, geometry=gdf['geometry'])\n",
    "gdf=gdf.to_crs(3163) ## change coordinates to RGNC\n",
    "gdf=gdf.set_crs(\"EPSG:3163\")\n",
    "gdf=gdf[[\"nom\", \"province\", \"commune\", \"surface\", \"geometry\",\"date_\",\"surface_id_h3\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "table = \"surfaces_brulees_brute_control\"\n",
    "\n",
    "conex = create_engine(f'postgresql://{os.getenv(\"DB_USER\")}:{os.getenv(\"DB_PWD\")}@{os.getenv(\"DB_HOST\")}:{os.getenv(\"DB_PORT\")}/{os.getenv(\"DB_WORKSPACE\")}')\n",
    "gdf.to_postgis(table, conex,schema=os.getenv(\"DB_SCHEMA\"),if_exists='append')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
