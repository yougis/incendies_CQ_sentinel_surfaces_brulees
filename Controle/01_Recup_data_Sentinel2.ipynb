{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile \".env\"\n",
    "\n",
    "PROJECT_ID=\"feux_cq\"\n",
    "\n",
    "COMMUN_PATH = \"C:/\"\n",
    "PATH_INFOCENTRE_APP = ${COMMUN_PATH}Informatique/SIG/Application/Jupyterhub/\n",
    "PATH_ETUDE = ${COMMUN_PATH}Informatique/SIG/Donnees/Oeil/Traitement_Donnees/SURFACES_BRULEES_SENTINEL/2022/220502_PreparationFeu2020/\n",
    "PROJECT_PATH =${COMMUN_PATH}Users/oriane.bruyere/Documents/Projet_feux/Script/Step1_detection_error/\n",
    "DATA_CATALOG_DIR = ${PATH_INFOCENTRE_APP}projets/catalogFiles/ \n",
    "DATA_OUTPUT_DIR = ${PROJECT_PATH}output/\n",
    "SIG_DATA_PATH = ${COMMUN_PATH}Informatique/SIG/Donnees/\n",
    "DB_USER=\"jfnguyenvansoc\"\n",
    "DB_PWD=\"oeil\"\n",
    "DB_HOST=\"172.20.12.13\"\n",
    "DB_PORT=5432\n",
    "\n",
    "DB_WORKSPACE=\"oeil_traitement\"\n",
    "DB_REF=\"oeil_reference\"\n",
    "DB_EXT=\"data_externe\"\n",
    "DB_SCHEMA = \"feux_cq\"\n",
    "DB_SCHEMA_REF = \"feux\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get missing burned areas files from INSIGHT server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "from filecmp import dircmp\n",
    "from os import listdir\n",
    "import os\n",
    "import filecmp \n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import fiona\n",
    "from sqlalchemy import create_engine\n",
    "load_dotenv()\n",
    "import subprocess\n",
    "from tobler.util import h3fy\n",
    "import h3\n",
    "from shapely.geometry import MultiPolygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open gpkg and add data to POSTGIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEMP ='A:/FEUX_INSIGHT/2018/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fichiers_geopackages = [f for f in os.listdir(DATA_TEMP) if f.endswith('.gpkg')]\n",
    "gdf_list = []\n",
    "\n",
    "for fichier_geopackage in fichiers_geopackages:\n",
    "    chemin_geopackage = os.path.join(DATA_TEMP, fichier_geopackage)\n",
    "    couches = fiona.listlayers(chemin_geopackage)\n",
    "\n",
    "    for couche in couches:\n",
    "        gdf_couches = gpd.read_file(chemin_geopackage, layer=couche, driver='GPKG')\n",
    "        \n",
    "        if 'date_' in gdf_couches.columns:\n",
    "            gdf_couches['date_']=pd.to_datetime(gdf_couches['date_'])\n",
    "            gdf_couches['date_']=gdf_couches['date_'].dt.date\n",
    "            gdf_couches['datetexte'] = gdf_couches['date_texte'].apply(lambda x: x[:-11] if len(x) > 8 else x)\n",
    "\n",
    "        elif 'date_texte' or 'date' in gdf_couches.columns:\n",
    "            gdf_couches.rename(columns={'date_texte': 'date_'}, inplace=True)\n",
    "            gdf_couches.rename(columns={'date': 'date_'}, inplace=True)\n",
    "            \n",
    "            gdf_couches['datetexte'] = gdf_couches['date_'].apply(lambda x: x[:-11] if len(x) > 8 else x)\n",
    "            gdf_couches['date_']=pd.to_datetime(gdf_couches['datetexte'])\n",
    "            gdf_couches['date_']=gdf_couches['date_'].dt.date\n",
    "\n",
    "    \n",
    "        gdf_couches['nom'] = gdf_couches['nom'].apply(lambda x: x[:19] + x[30:] if len(x) > 30 else x)\n",
    "        gdf_list.append(gdf_couches)\n",
    "\n",
    "gdf = pd.concat(gdf_list, ignore_index=True, sort=False)\n",
    "gdf=gdf.reset_index(drop=True)\n",
    "\n",
    "print(\"Données fusionnées à partir des GeoPackages :\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertir les surfaces detectees en type MULTIPOLYGONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier si la géométrie est de type Polygon\n",
    "if gdf['geometry'].geom_type[0] == 'Polygon':\n",
    "    gdf['geometry'] = gdf['geometry'].apply(lambda poly: MultiPolygon([poly]))\n",
    "\n",
    "    print(gdf)\n",
    "else:\n",
    "    print(\"La géométrie n'est pas de type Polygon.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajouter une identifiant H3 et créer un identifiant unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H3_res = 12\n",
    "def geo_to_h3(row):\n",
    "  return h3.geo_to_h3(row.lat,row.lon,resolution = H3_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf=gdf.to_crs(4326) ## change coordinates to WGS84\n",
    "gdf=gdf.set_crs(\"EPSG:4326\")\n",
    "\n",
    "gdf['centroides']=gdf['geometry'].centroid\n",
    "gdf['lon'] = gdf.centroides.x\n",
    "gdf['lat'] = gdf.centroides.y\n",
    "\n",
    "gdf['h3_id'] = gdf.apply(geo_to_h3,axis=1)\n",
    "\n",
    "gdf['surface_id_h3']=0\n",
    "for i in range(len(gdf)):\n",
    "  gdf['surface_id_h3'][i]=str(gdf['nom'][i][-10:])+\"_\"+str(gdf['datetexte'][i])+\"_\"+str(gdf['h3_id'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création de la base de donnée dans POSTGIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(gdf.copy(), crs=gdf.crs, geometry=gdf['geometry'])\n",
    "gdf=gdf.to_crs(3163) ## change coordinates to RGNC\n",
    "gdf=gdf.set_crs(\"EPSG:3163\")\n",
    "gdf=gdf[[\"nom\", \"province\", \"commune\", \"surface\", \"geometry\",\"date_\",\"surface_id_h3\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "table = \"surfaces_brulees_brute_control\"\n",
    "\n",
    "conex = create_engine(f'postgresql://{os.getenv(\"DB_USER\")}:{os.getenv(\"DB_PWD\")}@{os.getenv(\"DB_HOST\")}:{os.getenv(\"DB_PORT\")}/{os.getenv(\"DB_WORKSPACE\")}')\n",
    "gdf.to_postgis(table, conex,schema=os.getenv(\"DB_SCHEMA\"),if_exists='append')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
