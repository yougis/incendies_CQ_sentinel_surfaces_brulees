{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.4.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.2.min.js\", \"https://cdn.holoviz.org/panel/1.4.4/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n\ttry {\n          inline_js[i].call(root, root.Bokeh);\n\t} catch(e) {\n\t  if (!reloading) {\n\t    throw e;\n\t  }\n\t}\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, LineString, shape, mapping\n",
    "import networkx as nx\n",
    "import datetime as dt\n",
    "from pystac_client import Client\n",
    "from holoviews import opts\n",
    "from intake import open_catalog\n",
    "import panel as pn\n",
    "import numpy as np\n",
    "from bokeh.models import HoverTool, LogColorMapper, ColumnDataSource, DatetimeTickFormatter\n",
    "from bokeh.plotting import figure\n",
    "from odc.stac import configure_rio, stac_load\n",
    "import holoviews as hv\n",
    "from bokeh.models.formatters import DatetimeTickFormatter\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import hvplot.pandas \n",
    "from functools import reduce\n",
    "import divers\n",
    "from bokeh.models import GeoJSONDataSource\n",
    "import math\n",
    "from pyproj import Transformer\n",
    "\n",
    "load_dotenv()\n",
    "## panel serve 03_Dashboard_controle_V2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "catfeux = open_catalog(f'{os.getenv(\"DATA_CATALOG_DIR\")}Fire_Detection_Data_Quality.yaml')\n",
    "table_source='vue_sentinel_brute_no_geom'\n",
    "table_viirs_snpp='incendie_viirs_snpp_maj'\n",
    "table_viirs_noaa='incendie_viirs_noaa20_maj'\n",
    "fichier_tiles='list_of_tiles_2024'\n",
    "catalog_stac=\"https://earth-search.aws.element84.com/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_sentinel=catfeux.tile_sentinel2_line_UTM.read()\n",
    "tile_sentinel=tile_sentinel.to_crs(epsg=3857)\n",
    "\n",
    "nc_limits=catfeux.vue_nc_simplifiee.read()\n",
    "nc_limits=nc_limits.to_crs(epsg=3857)\n",
    "\n",
    "tile_sentinel['Name']='L2A_T'+tile_sentinel['Name']\n",
    "\n",
    "tile_centroid=tile_sentinel.copy()\n",
    "tile_centroid['centroid'] = tile_centroid.geometry.centroid\n",
    "centroid_tuile = pd.DataFrame({\n",
    "    'x': tile_centroid['centroid'].x,\n",
    "    'y': tile_centroid['centroid'].y,\n",
    "    'nom': tile_centroid['Name']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stac_search(date_start,date_end):\n",
    "\n",
    "    catalog = Client.open(catalog_stac)\n",
    "    query = catalog.search(\n",
    "        collections=[\"sentinel-2-l2a\"],datetime=(date_start).strftime('%Y-%m-%d')+'/'+(date_end).strftime('%Y-%m-%d'), bbox=[163.362, -22.76, 168.223, -19.479],       \n",
    "        fields={\"include\": [\"properties.grid:code\", \"properties.datetime\", \"properties.eo:cloud_cover\", \"assets.thumbnail.href\"], \"exclude\": []})\n",
    "\n",
    "    items = list(query.items())\n",
    "    stac_json = query.item_collection_as_dict()\n",
    "\n",
    "    gdf = gpd.GeoDataFrame.from_features(stac_json, \"epsg:4326\")\n",
    "    thumbnails = [item.assets['thumbnail'].href for item in items]\n",
    "\n",
    "    df = gdf.rename(columns={\n",
    "        'grid:code': 'nom',\n",
    "        'datetime': 'date_',\n",
    "        'eo:cloud_cover': 'Cloud_Cover',\n",
    "        'thumbnail.href': 'thumbnail'\n",
    "    })\n",
    "\n",
    "    df['nom'] = [x[5:] for x in df['nom']]\n",
    "    df['nom']='L2A_T'+df['nom'] \n",
    "\n",
    "    df=df.reset_index(drop=True)\n",
    "    date_formats = ['%Y-%m-%dT%H:%M:%SZ', '%Y-%m-%d %H:%M:%S.%f%z','%Y-%m-%dT%H:%M:%S.%fZ']\n",
    "    df['date_'] = df['date_'].apply(divers.try_multiple_date_formats, formats=date_formats)\n",
    "    df['date_'] = df['date_'].dt.strftime('%Y-%m-%d')\n",
    "    df['date_'] = pd.to_datetime(df['date_'])\n",
    "    \n",
    "    df['thumbnail_url'] = thumbnails\n",
    "    df = df.sort_values(by='date_', ascending=True)\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_table(date_range):\n",
    "\n",
    "    sql = f\"\"\"SELECT *\n",
    "    FROM feux_cq.{table_source} si\n",
    "    WHERE si.date_ >= '{pd.to_datetime(date_range[0]).strftime('%Y-%m-%d')}' AND si.date_ <= '{pd.to_datetime(date_range[1]).strftime('%Y-%m-%d')}'\n",
    "    \"\"\"\n",
    "    dataCatalog = getattr(catfeux, table_source)(sql_expr=sql)\n",
    "    df = dataCatalog.read()\n",
    "    \n",
    "    df['nom']=df['nom'].apply(lambda x: x[20:])\n",
    "    df['groupe_id'] = np.nan\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df,full_date_series,name,choix):\n",
    "    df_tiles = df.groupby(['date_', 'nom']).size().reset_index(name=name)\n",
    "    df_tiles = df_tiles[df_tiles['nom'] == choix]\n",
    "\n",
    "    df_tiles['date_'] = pd.to_datetime(df_tiles['date_'], errors='coerce')\n",
    "    df_tiles['date_'] = df_tiles['date_'].dt.strftime('%Y-%m-%d')\n",
    "    df_tiles['date_']=pd.to_datetime(df_tiles['date_'])\n",
    "\n",
    "    df_tiles = pd.merge(full_date_series, df_tiles, on='date_', how='left')\n",
    "    df_tiles['nom'] = df_tiles['nom'].fillna(choix)\n",
    "\n",
    "    return(df_tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viirs_data(data,stl2_poly):\n",
    "    \n",
    "    dataCatalog = getattr(catfeux, data)\n",
    "    df = dataCatalog.read()\n",
    "    df=df.to_crs(epsg=3857)\n",
    "    df = gpd.sjoin(stl2_poly, df, how='inner')\n",
    "    df['date_']=pd.to_datetime(df['BegDate'])\n",
    "\n",
    "    df['nom']=df['Name'] \n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_map(tot_surf_tile, min_size=10, max_size=30, color=\"orange\"):\n",
    "    tt = pd.merge(centroid_tuile, tot_surf_tile, on='nom', how='left')\n",
    "\n",
    "    tt = tt.rename(columns={0: 'surface'})\n",
    "    tt['surface'] = tt['surface'].replace(np.nan, 0)\n",
    "\n",
    "    min_value = tt['surface'].min()\n",
    "    max_value = tt['surface'].max()\n",
    "    mean_value = tt['surface'].mean()\n",
    "\n",
    "    max_val_leg = math.ceil(max_value / 10.0) * 10\n",
    "    mean_val_leg = math.ceil(mean_value / 10.0) * 10\n",
    "    intermediate_val_leg = (mean_val_leg + max_val_leg) / 2\n",
    "\n",
    "    legend_values = [min_value, mean_val_leg, intermediate_val_leg, max_val_leg]\n",
    "    legend_sizes = [divers.normalize_size(val, min_size, max_size, min_value, max_val_leg) for val in legend_values]\n",
    "\n",
    "    tt['normalized_size'] = tt['surface'].apply(divers.normalize_size, args=(min_size, max_size, min_value, max_val_leg))\n",
    "\n",
    "    tt['color'] = [color if val != 0 else 'black' for val in tt['surface']]\n",
    "\n",
    "    centroid_data_zero = tt[tt['surface'] == 0]\n",
    "    centroid_data_nonzero = tt[tt['surface'] != 0]\n",
    "    source_zero = ColumnDataSource(centroid_data_zero)\n",
    "    source_nonzero = ColumnDataSource(centroid_data_nonzero)\n",
    "\n",
    "    geo_source = GeoJSONDataSource(geojson=nc_limits.to_json())\n",
    "\n",
    "    tile_sentinel_geojson = gpd.GeoDataFrame(tile_sentinel).to_json()\n",
    "    tile = GeoJSONDataSource(geojson=tile_sentinel_geojson)\n",
    "\n",
    "    map = figure(width=800, title=\"Carte des surfaces brûlées estimées par tuiles pour les dates sélectionnées\",\n",
    "                 x_axis_type=\"mercator\", y_axis_type=\"mercator\")\n",
    "\n",
    "    map.patches('xs', 'ys', source=geo_source,\n",
    "                fill_alpha=1, fill_color='#d9d9d9',line_color=\"black\", line_width=0.4)  # plot of new caledonia land\n",
    "\n",
    "    map.multi_line('xs', 'ys', source=tile,\n",
    "                   line_alpha=1, line_color=\"black\", line_width=1)\n",
    "    \n",
    "    circles = map.circle('x', 'y', size='normalized_size', source=source_nonzero, color=color, line_color='black', fill_alpha=0.6)\n",
    "    squares = map.square('x', 'y', size='normalized_size', source=source_zero, color='black', line_color='black', fill_alpha=0.6)\n",
    "\n",
    "    hover = HoverTool(renderers=[circles, squares], tooltips=[\n",
    "        (\"Surface (ha)\", '@surface'),\n",
    "        ('Tuile', '@nom')\n",
    "    ])\n",
    "    map.add_tools(hover)\n",
    "    \n",
    "    lon, lat = 163.75, -23\n",
    "    transformer = Transformer.from_crs(\"EPSG:4326\", \"EPSG:3857\", always_xy=True)\n",
    "    x, y = transformer.transform(lon, lat)\n",
    "\n",
    "    legend_data = []\n",
    "    xL, yL = x - 45000, y + 20000\n",
    "    for i, value in enumerate(legend_values):\n",
    "        size = divers.normalize_size(value, min_size, max_size, min_value, max_val_leg)\n",
    "        legend_data.append({'xL': xL, 'yL': yL + i * 40000, 'value': value, 'size': size})\n",
    "    \n",
    "    legend_data.append({'xL': xL, 'yL': yL + len(legend_values) * 40000, 'value': 0, 'size': min_size})\n",
    "    legend_df = pd.DataFrame(legend_data)\n",
    "    legend_source_nonzero = ColumnDataSource(legend_df[legend_df['value'] != 0])\n",
    "    legend_source_zero = ColumnDataSource(legend_df[legend_df['value'] == 0])\n",
    "\n",
    "    legend_circles = map.circle('xL', 'yL', size='size', source=legend_source_nonzero, color=color, line_color='black', fill_alpha=0.6)\n",
    "    legend_squares = map.square('xL', 'yL', size='size', source=legend_source_zero, color='black', line_color='black', fill_alpha=0.6)\n",
    "\n",
    "    for idx, row in legend_df.iterrows():\n",
    "        map.text(x=row['xL'] + 20000, y=row['yL'], text=[str(round(row['value'], 2))], text_align='left', text_baseline='middle', text_font_size='8pt')\n",
    "\n",
    "    return map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_insight_tile(data):\n",
    "    \n",
    "    dataCatalog = getattr(catfeux, data)\n",
    "    tile_insight= dataCatalog.read()\n",
    "\n",
    "    tile_insight['date_'] = tile_insight[0].str.extract(r'(\\d{8})')\n",
    "    tile_insight['date_']=pd.to_datetime(tile_insight['date_'])\n",
    "    tile_insight['nom'] = tile_insight[0].str.extract(r'(L2A_T\\w+)_D')[0]\n",
    "    tile_insight['value']=1\n",
    "\n",
    "    return(tile_insight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Start creation of dashboard\n",
    "\n",
    "pn.extension()\n",
    "pn.extension('tabulator')\n",
    "\n",
    "stylesheet = \"\"\"\n",
    ".tabulator-cell {\n",
    "    font-size: 20px;\n",
    "}\n",
    "\"\"\"\n",
    "custom_style = {\n",
    "    'background': '#f89424',\n",
    "    'border': '1px solid black',\n",
    "    'padding': '10px',\n",
    "    'box-shadow': '5px 5px 5px #bcbcbc'\n",
    "}\n",
    "    \n",
    "tile_bouton = pn.widgets.RadioButtonGroup(options=['L2A_T58KCC','L2A_T58KCD','L2A_T58KDB','L2A_T58KDC','L2A_T58KEA','L2A_T58KEB','L2A_T58KEC',\n",
    "            'L2A_T58KFA','L2A_T58KFB','L2A_T58KFC','L2A_T58KGA','L2A_T58KGB','L2A_T58KGC','L2A_T58KGV','L2A_T58KHB'],align='center',stylesheets=[stylesheet],\n",
    "            button_type='warning',button_style='outline',name='Choose a tile')\n",
    "\n",
    "### PAGE 1 #########\n",
    "############ table\n",
    "\n",
    "def maj_table(date_range,table_source):\n",
    "    hv.extension('bokeh')\n",
    "\n",
    "    global stac_search_results, df\n",
    "    \n",
    "    df=read_table(date_range)\n",
    "    stac_search_results=stac_search(df['date_'].min(),df['date_'].max())\n",
    "    \n",
    "    #df['date_'] = pd.to_datetime(df['date_'])\n",
    "\n",
    "    G = nx.Graph()\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        intersecting_ids = divers.find_intersecting_id(row, df)\n",
    "        for id_ in intersecting_ids:\n",
    "            G.add_edge(row['surface_id_h3'], id_)\n",
    "\n",
    "    groupes = list(nx.connected_components(G))\n",
    "\n",
    "    for groupe_id, groupe in enumerate(groupes):\n",
    "        for id_ in groupe:\n",
    "            df.loc[df['surface_id_h3'] == id_, 'groupe_id'] = groupe_id\n",
    "\n",
    "    pluri_tile_surface,pluri_tile_number,pluri_detection_group,pluri_detection_surface=divers.mesure_pluri_detection(df)\n",
    "    mono_tile_surface,mono_tile_number,mono_detection_group,mono_detection_surface=divers.mesure_mono_detection(df)\n",
    "    tot_surf,nb_tot,tot_surf_tile=divers.mesure_totale(df)\n",
    "    print(tot_surf_tile)\n",
    "    dataframes = [mono_tile_number, mono_tile_surface, pluri_tile_number, pluri_tile_surface]\n",
    "    info_surfaces = reduce(lambda left, right: pd.merge(left, right, on='nom', how='outer'), dataframes)\n",
    "\n",
    "    info_surfaces=info_surfaces.rename(columns={'nom':'Tile name','count_x':'Number of mono detection','surface':'Sum of mono detected area','count_y':'Number of pluri detection',0:'Sum of pluri detected area'})\n",
    "    info_surfaces=info_surfaces.round(2)\n",
    "\n",
    "    table = pn.widgets.Tabulator(info_surfaces, name=\"Informations à l'échelle des tuiles Sentinel-2\",header_align='center', show_index=False,\n",
    "                stylesheets=[stylesheet])\n",
    "\n",
    "#################################    \n",
    "\n",
    "    map=create_map(tot_surf_tile)\n",
    "\n",
    "    return(table,map,nb_tot,tot_surf,mono_detection_group,pluri_detection_group,mono_detection_surface,pluri_detection_surface)\n",
    "\n",
    "############################\n",
    "\n",
    "def maj_graphic(date_range,choix):\n",
    "    global stac_search_results, df\n",
    "\n",
    "    tile_insight=read_insight_tile(fichier_tiles)\n",
    "\n",
    "    viirs_snpp=viirs_data(table_viirs_snpp,tile_sentinel)\n",
    "    viirs_noaa=viirs_data(table_viirs_noaa,tile_sentinel)\n",
    "\n",
    "    viirs_snpp=viirs_snpp[(viirs_snpp['date_'] >= pd.to_datetime(date_range[0]).strftime('%Y-%m-%d')) & (viirs_snpp['date_']<=pd.to_datetime(date_range[1]).strftime('%Y-%m-%d'))]\n",
    "    viirs_noaa=viirs_noaa[(viirs_noaa['date_'] >= pd.to_datetime(date_range[0]).strftime('%Y-%m-%d')) & (viirs_noaa['date_']<=pd.to_datetime(date_range[1]).strftime('%Y-%m-%d'))]\n",
    "    tile_insight=tile_insight[(tile_insight['date_'] >= pd.to_datetime(date_range[0]).strftime('%Y-%m-%d')) & (tile_insight['date_']<=pd.to_datetime(date_range[1]).strftime('%Y-%m-%d'))]\n",
    "\n",
    "    date_range = pd.date_range(start=df['date_'].min(), end=df['date_'].max())\n",
    "    full_date_series = pd.DataFrame(date_range.strftime('%Y-%m-%d'), columns=['date_'])\n",
    "    full_date_series['date_']=pd.to_datetime(full_date_series['date_'])\n",
    "    \n",
    "    df_tiles=prepare_data(df,full_date_series,\"Sentinel-2\",choix)\n",
    "    snpp=prepare_data(viirs_snpp,full_date_series,\"Snpp\",choix)\n",
    "    noaa=prepare_data(viirs_noaa,full_date_series,\"Noaa-20\",choix)\n",
    "    insight=prepare_data(tile_insight,full_date_series,\"INSIGHT\",choix)\n",
    "\n",
    "    df_cloud_cover=stac_search_results[stac_search_results['nom'] == choix]\n",
    "\n",
    "    dataframes = [df_tiles, df_cloud_cover, noaa, snpp,insight]\n",
    "    df_tot = reduce(lambda left, right: pd.merge(left, right, on='date_', how='left', suffixes=('', '_y')), dataframes)\n",
    "    df_tot = df_tot.loc[:, ~df_tot.columns.str.endswith('_y')]\n",
    "\n",
    "    bar_plot=df_tot.hvplot(x='date_',y=['Sentinel-2', 'Snpp','Noaa-20'], kind='bar', width=800, height=400, title=\"Nombre de détection par jour\", legend='top_left').opts(multi_level=False,\n",
    "                                                                                                                                            xlabel='Date')\n",
    "    cc_fig = df_tot.hvplot.scatter(x='date_', y='Cloud_Cover', color=df_tot['INSIGHT'].apply(lambda x: 'red' if x == 1 else 'black'), marker='s', size=300)\n",
    "    red_patch = hv.Scatter([], label='Tuile présente').opts(color='red', marker='s', size=60)\n",
    "    black_patch = hv.Scatter([], label='Tuile absente').opts(color='black', marker='s', size=60)\n",
    "\n",
    "    combined = hv.Layout([bar_plot, cc_fig]).cols(1)\n",
    "    combined.opts(\n",
    "        opts.Scatter(height=400, width=1800, xrotation=45, responsive=True,title='Evolution de la couverture nuageuse (%)',shared_axes=True,show_legend=True),\n",
    "        opts.Bars(height=600, width=1800, xrotation=45, responsive=True,title=\"Nombre de détection par jour\",shared_axes=True, show_legend=True),\n",
    "        opts.Layout(shared_axes=True))\n",
    "\n",
    "    image_elements = []\n",
    "    for _, row in df_cloud_cover.iterrows():\n",
    "        url = row['thumbnail_url']\n",
    "        response = requests.get(url)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        img_array = np.array(img)\n",
    "        image_elements.append(hv.RGB(img_array).opts(title=f\"Date: {row['date_'].date()}, Cloud: {row['Cloud_Cover']}%\"))\n",
    "\n",
    "    grid = hv.Layout(image_elements).opts(opts.RGB(width=500, height=500, xaxis=None, yaxis=None)).cols(3)\n",
    "    grid = hv.Layout(grid).opts(width=1200,height=600)\n",
    "\n",
    "    return combined,grid\n",
    "\n",
    "total_detection=pn.indicators.Number(name='Totale détection', value=0, format='{value}',colors=[(0,'blue')])\n",
    "surface_total=pn.indicators.Number(name='Surface totale estimée (ha)', value=0, format='{value}',colors=[(0,'blue')])\n",
    "mono_detection_group=pn.indicators.Number(name='Nombre de Mono détection', value=0, format='{value}',colors=[(0,'red')])\n",
    "pluri_detection_group=pn.indicators.Number(name='Nombre de Pluri détections', value=0, format='{value}',colors=[(0,'green')])\n",
    "mono_detection_surface=pn.indicators.Number(name='Surface (ha) Mono détection', value=0, format='{value}',colors=[(0,'red')])\n",
    "pluri_detection_surface=pn.indicators.Number(name='Surface (ha) Pluri détections', value=0, format='{value}',colors=[(0,'green')])\n",
    "\n",
    "table_map_container = pn.Row()  \n",
    "graphic_container = pn.Column() \n",
    "interface_1_container = pn.Column()\n",
    "\n",
    "def update_interface_1(event):\n",
    "    global table_map_container\n",
    "    \n",
    "    table, map, nb_tot, tot_surf, mono_nb, pluri_nb, mono_surf, pluri_surf = maj_table(datetime_range_picker.value,table_source) \n",
    "    mono_detection_group.value = mono_nb\n",
    "    pluri_detection_group.value = pluri_nb\n",
    "    \n",
    "    mono_detection_surface.value = mono_surf\n",
    "    pluri_detection_surface.value = pluri_surf\n",
    "\n",
    "    total_detection.value = nb_tot\n",
    "    surface_total.value = tot_surf\n",
    "    \n",
    "    table_map_container[:] = [table, map]\n",
    "    interface_1_container[:] = [table_map_container, tile_bouton]\n",
    "    \n",
    "    if interface_1_container not in main:\n",
    "        main.append(interface_1_container)\n",
    "    if graphic_container not in main:\n",
    "        main.append(graphic_container)\n",
    "\n",
    "def update_interface_2(event):\n",
    "    global graphic_container\n",
    "    \n",
    "    choix = event.new\n",
    "    fig, image = maj_graphic(datetime_range_picker.value, tile_bouton.value)\n",
    "    graphic_container[:] = [fig, image]    \n",
    "\n",
    "datetime_range_picker = pn.widgets.DatetimeRangePicker(name='Select your Date Range', start=dt.datetime(2023, 1, 1), end=dt.datetime(2024, 12, 31))\n",
    "datetime_range_picker.param.watch(update_interface_1, 'value')\n",
    "\n",
    "tile_bouton.param.watch(update_interface_2, 'value')\n",
    "\n",
    "sidebar = pn.Column(datetime_range_picker,\"# Indicateurs Globaux\", total_detection,surface_total,mono_detection_group, mono_detection_surface,pluri_detection_group,pluri_detection_surface)\n",
    "main = pn.Column(\"## Step 1 : Selectionner un intervalle de date pour voir les données et indicateurs globaux. \\n ## Step 2 : Choisir une ZAE à observer\") \n",
    "\n",
    "template =pn.template.FastListTemplate(\n",
    "    site=\"Panel\", header_background ='#f89424',title=\"Dashboard Contrôle des surfaces brûlées en sortie en chaîne\",logo=\"https://neotech.nc/wp-content/uploads/2023/10/logo_oeil_quadri-254x300.jpeg.webp\",sidebar=[sidebar],main=[main])\n",
    "\n",
    "template.servable()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
